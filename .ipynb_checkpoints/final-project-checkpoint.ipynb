{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2bd048",
   "metadata": {},
   "source": [
    "# How post-game LoL stats affect the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9911d1",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "[League of Legends](https://en.wikipedia.org/wiki/League_of_Legends) is a multiple online battle arena (MOBA) video game that involves two teams of five players. Each team wins by destroying the enemy \"nexus\" located in the enemy base. Each player earns experience points (exp) and gold to give their character extra statistics in order to defeat the enemy. \n",
    "\n",
    "In this project, I will be classifying League of Legends games as either `win` or `loss` based on player game statistics at the end of the game, such as number of kills/deaths, gold earned, and damage dealt. I will explore how these different statistics in the game affect the outcome of these games. In particular, I will be looking at my own ranked solo/duo games under the summoner name `Mirinda`.  \n",
    "\n",
    "I will be obtaining my data through the [RiotAPI](https://developer.riotgames.com/apis). I will pull a list of matches and choose a particular player to view their statistics.\n",
    "\n",
    "In order to explore how different post-game statistics affect the outcome of the game, I will train multiple classifications models using different sets of features. These classification models are as follows:\n",
    "\n",
    "- Perceptron\n",
    "- Adaline SGD\n",
    "- Logistic regression\n",
    "- Decision tree\n",
    "\n",
    "\n",
    "In each of these models, I will train 10 different models for each set of features. I will then test each model with 10 sets of testing data. I will record the accuracy of the trained models for different sets of features and compare the overall averages of each different model for each set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fefbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc9017",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "I have obtained my data through the RiotAPI using a Python script with the `riotwatcher` package.  I pulled a list of 907 matches. Through each match, I iterated through each `participant` and pulled game results for `Mirinda`. I then wrote this data obtained onto a CSV file. \n",
    "\n",
    "Each match contains a list of 54 different statistics (see`df.columns`). These will be used as possible features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d32e476",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assists', 'bountyLevel', 'champExperience', 'champLevel',\n",
       "       'consumablesPurchased', 'damageDealtToBuildings',\n",
       "       'damageDealtToObjectives', 'damageDealtToTurrets',\n",
       "       'damageSelfMitigated', 'deaths', 'detectorWardsPlaced', 'doubleKills',\n",
       "       'goldEarned', 'goldSpent', 'killingSprees', 'kills',\n",
       "       'largestCriticalStrike', 'largestKillingSpree', 'largestMultiKill',\n",
       "       'longestTimeSpentLiving', 'magicDamageDealt',\n",
       "       'magicDamageDealtToChampions', 'magicDamageTaken',\n",
       "       'neutralMinionsKilled', 'pentaKills', 'physicalDamageDealt',\n",
       "       'physicalDamageDealtToChampions', 'physicalDamageTaken', 'quadraKills',\n",
       "       'sightWardsBoughtInGame', 'spell1Casts', 'spell2Casts', 'spell3Casts',\n",
       "       'spell4Casts', 'timeCCingOthers', 'timePlayed', 'totalDamageDealt',\n",
       "       'totalDamageDealtToChampions', 'totalDamageShieldedOnTeammates',\n",
       "       'totalDamageTaken', 'totalHeal', 'totalHealsOnTeammates',\n",
       "       'totalMinionsKilled', 'totalTimeCCDealt', 'totalTimeSpentDead',\n",
       "       'totalUnitsHealed', 'tripleKills', 'trueDamageDealt',\n",
       "       'trueDamageDealtToChampions', 'trueDamageTaken', 'visionScore',\n",
       "       'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'win',\n",
       "       'matchID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('game-data.csv',\n",
    "                     encoding='utf-8')\n",
    "# possible features exluding `win` and `matchID`\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1ebcd",
   "metadata": {},
   "source": [
    "### Feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872af7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: all\n",
    "X_all = df.iloc[:, :54]\n",
    "X_all = np.array(X_all)\n",
    "\n",
    "# features: player combat -- offensive\n",
    "# 'largestCriticalStrike', 'magicDamageDealt','magicDamageDealtToChampions', 'physicalDamageDealt',\n",
    "# 'physicalDamageDealtToChampions', 'totalDamageDealt', 'totalDamageDealtToChampions'\n",
    "# 'trueDamageDealt', 'trueDamageDealtToChampions',\n",
    "X_pcombatOff = df.iloc[:, [16, 20, 21, 25, 26, 36, 37, 47, 48]]\n",
    "X_pcombatOff = np.array(X_pcombatOff)\n",
    "\n",
    "# features: player combat -- defensive\n",
    "# 'damageSelfMitigated', 'magicDamageTaken', 'physicalDamageTaken', 'totalDamageShieldedOnTeammates', 'totalDamageTaken', \n",
    "# 'totalHeal', 'totalHealsOnTeammates', 'trueDamageTaken'\n",
    "X_pcombatDef = df.iloc[:, [8, 22, 27, 38, 39, 40, 41, 49]]\n",
    "X_pcombatDef = np.array(X_pcombatDef)\n",
    "\n",
    "# features: player combat -- offensive AND defensive\n",
    "X_pcombat = df.iloc[:, [16, 20, 21, 25, 26, 36, 37, 47, 48, 8, 22, 27, 38, 39, 40, 41, 49]]\n",
    "X_pcombat = np.array(X_pcombat)\n",
    "\n",
    "# features: spell casts\n",
    "# 'spell1Casts', 'spell2Casts', 'spell3Casts','spell4Casts'\n",
    "X_spells = df.iloc[:, [30, 31, 32, 33]]\n",
    "X_spells = np.array(X_spells)\n",
    "\n",
    "# features: KDA, kill streaks\n",
    "# 'assists', 'bountyLevel', 'deaths', 'doubleKills', 'killingSprees', 'kills',\n",
    "# 'largestKillingSpree', 'largestMultiKill', 'pentaKills', 'quadraKills', 'tripleKills',\n",
    "X_kda = df.iloc[:, [0, 1, 9, 11, 14, 15, 17, 18, 24, 28, 46]]\n",
    "X_kda = np.array(X_kda)\n",
    "\n",
    "# features: vision\n",
    "# 'detectorWardsPlaced', 'sightWardsBoughtInGame', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced'\n",
    "X_vision = df.iloc[:, [10, 29, 50, 51, 52, 53]]\n",
    "X_vision = np.array(X_vision)\n",
    "\n",
    "# list of different sets of features\n",
    "features_list = [X_all, X_pcombatOff, X_pcombatDef, X_pcombat, X_spells, X_kda, X_vision]\n",
    "\n",
    "# classes\n",
    "y = df.iloc[:, 54].values\n",
    "# True = 1, False = 0\n",
    "y = np.where(y, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b78a48",
   "metadata": {},
   "source": [
    "### Split data into training/testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e17531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "split_data(): split data into n sets of training and testing sets with a 70/30 split respectively, and standardize training set\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        features - set of features as an array\n",
    "        targets - classes\n",
    "    output:\n",
    "        dictionary of data splits:\n",
    "            dataSplits[random_state] = [X_train_std, X_test_std, y_train, y_test]\n",
    "\"\"\"\n",
    "\n",
    "def split_data(randomStart, randomEnd, features, targets):\n",
    "\n",
    "    # dataSplits[random_state] = [X_train_std, X_test_std, y_train, y_test]\n",
    "    dataSplits = {}\n",
    "    \n",
    "    for i in range(randomStart, randomEnd):\n",
    "        # Split data into testing and training \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=i, stratify=targets)\n",
    "\n",
    "        # Standardize training set\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "\n",
    "        # add split to dictionary\n",
    "        dataSplits[i] = [X_train_std, X_test_std, y_train, y_test]\n",
    "        \n",
    "    return dataSplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fb192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_all_split = split_data(1, 11, X_all, y)\n",
    "X_pcombatOff_split = split_data(1, 11, X_pcombatOff, y)\n",
    "X_pcombatDef_split = split_data(1, 11, X_pcombatDef, y)\n",
    "X_pcombat_split = split_data(1, 11, X_pcombat, y)\n",
    "X_spells_split = split_data(1, 11, X_spells, y)\n",
    "X_kda_split = split_data(1, 11, X_kda, y)\n",
    "X_vision_split = split_data(1, 11, X_vision, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d605d0",
   "metadata": {},
   "source": [
    "### Train Perceptron models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e15c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "train_perceptrons(): train n different perceptron models and test each n times\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        dataSplits - dictionary of data splits\n",
    "    output:\n",
    "        dictionary of perceptron models:\n",
    "            ppns[Perceptron model] = [(Misclassified examples, Accuracy)...]\n",
    "\"\"\"\n",
    "\n",
    "def train_perceptrons(randomStart, randomEnd, dataSplits):\n",
    "        \n",
    "    # ppns[Perceptron model] = [(Misclassified examples, Accuracy)...]\n",
    "    ppns = {}\n",
    "\n",
    "    for randState in dataSplits:\n",
    "\n",
    "        # current testing and training split\n",
    "        currentSplit = dataSplits[randState]\n",
    "\n",
    "        # list of models for each random state\n",
    "        results = []\n",
    "\n",
    "        # Train Perceptron model\n",
    "        ppn = Perceptron(eta0=0.1, random_state=randState)\n",
    "        ppn.fit(currentSplit[0], currentSplit[2]) # X_train_std, y_train\n",
    "\n",
    "        # test Perceptron model x times\n",
    "        for i in range(randomStart, randomEnd):\n",
    "\n",
    "            # put results into dict\n",
    "            y_pred = ppn.predict(dataSplits[i][1]) # X_test_std\n",
    "\n",
    "            # append tuple (Misclassified examples, Accuracy) ==> (y_test != y_pred).sum(), accuracy_score(y_test, y_pred))\n",
    "            results.append(((dataSplits[i][3] != y_pred).sum(), accuracy_score(dataSplits[i][3], y_pred)))\n",
    "            \n",
    "        # append results to current perceptron dict\n",
    "        ppns[ppn] = results\n",
    "        \n",
    "    return ppns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece4265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print_avgs(): print average misclassified examples and average accuracy\n",
    "    input:\n",
    "        model_dict - dictionary of models:\n",
    "            model_dict[model] = [(Misclassified examples, Accuracy)...]\n",
    "    output:\n",
    "        array containing average misclassified examples and average accuracy:\n",
    "            [average misclassified examples, average accuracy]\n",
    "\"\"\"\n",
    "def print_avgs(model_dict):\n",
    "    \n",
    "    total = len(model_dict)*len(model_dict[list(model_dict.keys())[0]])\n",
    "    sums = []\n",
    "    \n",
    "    for model in model_dict:\n",
    "        results = model_dict[model]\n",
    "        sums.append([sum(tup) for tup in zip(*results)])\n",
    "\n",
    "    final_list = [sum(value) for value in zip(*sums)]\n",
    "    final_list = [x / total for x in final_list]\n",
    "    \n",
    "    print('Avg misclassified examples: %d' % final_list[0])\n",
    "    print('Avg accuracy: %.3f' % final_list[1])\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e86d2",
   "metadata": {},
   "source": [
    "### Train Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97424c84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 25\n",
      "Avg accuracy: 0.906\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on all features\n",
    "ppns_all = train_perceptrons(1, 11, X_all_split)\n",
    "ppns_all_results = print_avgs(ppns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebb3473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 125\n",
      "Avg accuracy: 0.538\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on player combat -- offensive\n",
    "ppns_pcombatOff = train_perceptrons(1, 11, X_pcombatOff_split)\n",
    "ppns_pcombatOff_results = print_avgs(ppns_pcombatOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd01b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 94\n",
      "Avg accuracy: 0.652\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on player combat -- defensive\n",
    "ppns_pcombatDef = train_perceptrons(1, 11, X_pcombatDef_split)\n",
    "ppns_pcombatDef_results = print_avgs(ppns_pcombatDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b868ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 78\n",
      "Avg accuracy: 0.712\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on player combat -- both\n",
    "ppns_pcombat = train_perceptrons(1, 11, X_pcombat_split)\n",
    "ppns_pcombat_results = print_avgs(ppns_pcombat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ffefdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 131\n",
      "Avg accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on spell casts\n",
    "ppns_spells = train_perceptrons(1, 11, X_spells_split)\n",
    "ppns_spells_results = print_avgs(ppns_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e30d5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 51\n",
      "Avg accuracy: 0.812\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on kda/killing sprees\n",
    "ppns_kda = train_perceptrons(1, 11, X_kda_split)\n",
    "ppns_kda_results = print_avgs(ppns_kda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625dbf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 118\n",
      "Avg accuracy: 0.566\n"
     ]
    }
   ],
   "source": [
    "# train Perceptrons on vision\n",
    "ppns_vision = train_perceptrons(1, 11, X_vision_split)\n",
    "ppns_vision_results = print_avgs(ppns_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba1a22",
   "metadata": {},
   "source": [
    "### Perceptron results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1452c941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg misclassified examples</th>\n",
       "      <th>Avg accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>25.54</td>\n",
       "      <td>0.906447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA/kill streaks</th>\n",
       "      <td>51.45</td>\n",
       "      <td>0.811538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat</th>\n",
       "      <td>78.53</td>\n",
       "      <td>0.712344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (defensive)</th>\n",
       "      <td>94.95</td>\n",
       "      <td>0.652198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vision</th>\n",
       "      <td>118.48</td>\n",
       "      <td>0.566007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (offensive)</th>\n",
       "      <td>125.99</td>\n",
       "      <td>0.538498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spells casted</th>\n",
       "      <td>131.79</td>\n",
       "      <td>0.517253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Avg misclassified examples  Avg accuracy\n",
       "All features                                    25.54      0.906447\n",
       "KDA/kill streaks                                51.45      0.811538\n",
       "Player combat                                   78.53      0.712344\n",
       "Player combat (defensive)                       94.95      0.652198\n",
       "Vision                                         118.48      0.566007\n",
       "Player combat (offensive)                      125.99      0.538498\n",
       "Spells casted                                  131.79      0.517253"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_about =  [\"All features\", \"Player combat (offensive)\", \"Player combat (defensive)\",\n",
    "                  \"Player combat\", \"Spells casted\", \"KDA/kill streaks\", \"Vision\"]\n",
    "ppn_results_list = [ppns_all_results, ppns_pcombatOff_results, ppns_pcombatDef_results, \n",
    "                  ppns_pcombat_results, ppns_spells_results, ppns_kda_results, ppns_vision_results]\n",
    "\n",
    "ppn_results = pd.DataFrame(ppn_results_list, index = features_about, columns = [\"Avg misclassified examples\", \"Avg accuracy\"])\n",
    "ppn_results = ppn_results.sort_values(by=[\"Avg accuracy\"], ascending=False)\n",
    "ppn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93631661",
   "metadata": {},
   "source": [
    "### Train Adaline SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92120638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineSGD:\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    shuffle : bool (default: True)\n",
    "      Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "        Bias unit after fitting.\n",
    "    losses_ : list\n",
    "      Mean squared error loss function value averaged over all\n",
    "      training examples in each epoch.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        self.losses_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                X, y = self._shuffle(X, y)\n",
    "            losses = []\n",
    "            for xi, target in zip(X, y):\n",
    "                losses.append(self._update_weights(xi, target))\n",
    "            avg_loss = np.mean(losses)\n",
    "            self.losses_.append(avg_loss)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(X.shape[1])\n",
    "        if y.ravel().shape[0] > 1:\n",
    "            for xi, target in zip(X, y):\n",
    "                self._update_weights(xi, target)\n",
    "        else:\n",
    "            self._update_weights(X, y)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=m)\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.w_initialized = True\n",
    "        \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
    "        output = self.activation(self.net_input(xi))\n",
    "        error = (target - output)\n",
    "        self.w_ += self.eta * 2.0 * xi * (error)\n",
    "        self.b_ += self.eta * 2.0 * error\n",
    "        loss = error**2\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e989efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_adalineSGDs(): train n different Adaline SGD models and test each n times\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        dataSplits - dictionary of data splits\n",
    "    output:\n",
    "        dictionary of Adaline SGD models:\n",
    "            aSGDs[Adaline SGD model] = [(Misclassified examples, Accuracy)...]\n",
    "\"\"\"\n",
    "def train_adalineSGDs(randomStart, randomEnd, dataSplits):\n",
    "        \n",
    "    # aSGDs[Adaline SGD model] = [(Misclassified examples, Accuracy)...]\n",
    "    aSGDs = {}\n",
    "\n",
    "    for randState in dataSplits:\n",
    "\n",
    "        # current testing and training split\n",
    "        currentSplit = dataSplits[randState]\n",
    "\n",
    "        # list of models for each random state\n",
    "        results = []\n",
    "\n",
    "        # Train Adaline SGD model\n",
    "        aSGD = AdalineSGD(n_iter=30, eta=0.01, random_state=randState)\n",
    "        aSGD.fit(currentSplit[0], currentSplit[2]) # X_train_std, y_train\n",
    "\n",
    "        # test Adaline SGD model x times\n",
    "        for i in range(randomStart, randomEnd):\n",
    "\n",
    "            # put results into dict\n",
    "            y_pred = aSGD.predict(dataSplits[i][1]) # X_test_std\n",
    "\n",
    "            # append tuple (Misclassified examples, Accuracy) ==> (y_test != y_pred).sum(), accuracy_score(y_test, y_pred))\n",
    "            results.append(((dataSplits[i][3] != y_pred).sum(), accuracy_score(dataSplits[i][3], y_pred)))\n",
    "            \n",
    "        # append results to current perceptron dict\n",
    "        aSGDs[aSGD] = results\n",
    "        \n",
    "    return aSGDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5398ebc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 134\n",
      "Avg accuracy: 0.508\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on all features\n",
    "aSGDs_all = train_adalineSGDs(1, 11, X_all_split)\n",
    "aSGDs_all_results = print_avgs(aSGDs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79471087",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 146\n",
      "Avg accuracy: 0.462\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on player combat -- offensive\n",
    "aSGDs_pcombatOff = train_adalineSGDs(1, 11, X_pcombatOff_split)\n",
    "aSGDs_pcombatOff_results = print_avgs(aSGDs_pcombatOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c1f481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 78\n",
      "Avg accuracy: 0.713\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on player combat -- defensive\n",
    "aSGDs_pcombatDef = train_adalineSGDs(1, 11, X_pcombatDef_split)\n",
    "aSGDs_pcombatDef_results = print_avgs(aSGDs_pcombatDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c89224c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 131\n",
      "Avg accuracy: 0.518\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on player combat -- both\n",
    "aSGDs_pcombat = train_adalineSGDs(1, 11, X_pcombat_split)\n",
    "aSGDs_pcombat_results = print_avgs(aSGDs_pcombat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d446c460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 127\n",
      "Avg accuracy: 0.533\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on spell casts\n",
    "aSGDs_spells = train_adalineSGDs(1, 11, X_spells_split)\n",
    "aSGDs_spells_results = print_avgs(aSGDs_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1db235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 145\n",
      "Avg accuracy: 0.467\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on kda/killing sprees\n",
    "aSGDs_kda = train_adalineSGDs(1, 11, X_kda_split)\n",
    "aSGDs_kda_results = print_avgs(aSGDs_kda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ccafc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 104\n",
      "Avg accuracy: 0.618\n"
     ]
    }
   ],
   "source": [
    "# train Adaline SGD on vision\n",
    "aSGDs_vision = train_adalineSGDs(1, 11, X_vision_split)\n",
    "aSGDs_vision_results = print_avgs(aSGDs_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebf323",
   "metadata": {},
   "source": [
    "### AdalineSGD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af63e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg misclassified examples</th>\n",
       "      <th>Avg accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Player combat (defensive)</th>\n",
       "      <td>78.27</td>\n",
       "      <td>0.713297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vision</th>\n",
       "      <td>104.32</td>\n",
       "      <td>0.617875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spells casted</th>\n",
       "      <td>127.52</td>\n",
       "      <td>0.532894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat</th>\n",
       "      <td>131.69</td>\n",
       "      <td>0.517619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>134.42</td>\n",
       "      <td>0.507619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA/kill streaks</th>\n",
       "      <td>145.49</td>\n",
       "      <td>0.467070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (offensive)</th>\n",
       "      <td>146.80</td>\n",
       "      <td>0.462271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Avg misclassified examples  Avg accuracy\n",
       "Player combat (defensive)                       78.27      0.713297\n",
       "Vision                                         104.32      0.617875\n",
       "Spells casted                                  127.52      0.532894\n",
       "Player combat                                  131.69      0.517619\n",
       "All features                                   134.42      0.507619\n",
       "KDA/kill streaks                               145.49      0.467070\n",
       "Player combat (offensive)                      146.80      0.462271"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aSGD_results_list = [aSGDs_all_results, aSGDs_pcombatOff_results, aSGDs_pcombatDef_results, \n",
    "                  aSGDs_pcombat_results, aSGDs_spells_results, aSGDs_kda_results, aSGDs_vision_results]\n",
    "\n",
    "aSGD_results = pd.DataFrame(aSGD_results_list, index = features_about, columns = [\"Avg misclassified examples\", \"Avg accuracy\"])\n",
    "aSGD_results = aSGD_results.sort_values(by=[\"Avg accuracy\"], ascending=False)\n",
    "aSGD_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb30a84",
   "metadata": {},
   "source": [
    "### Train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2de1fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\"\"\"\n",
    "train_lrGDs(): train n different logistic regression GD models and test each n times\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        dataSplits - dictionary of data splits\n",
    "    output:\n",
    "        dictionary of logistic regression GD models:\n",
    "            lrGDs[logistic regression GD model] = [(Misclassified examples, Accuracy)...]\n",
    "\"\"\"\n",
    "def train_lrGDs(randomStart, randomEnd, dataSplits):\n",
    "        \n",
    "    # lrGDs[logistic regression GD model] = [(Misclassified examples, Accuracy)...]\n",
    "    lrGDs = {}\n",
    "\n",
    "    for randState in dataSplits:\n",
    "\n",
    "        # current testing and training split\n",
    "        currentSplit = dataSplits[randState]\n",
    "\n",
    "        # list of models for each random state\n",
    "        results = []\n",
    "\n",
    "        # Train logistic regression GD model\n",
    "        lrGD = LogisticRegression(random_state=randState)\n",
    "        lrGD.fit(currentSplit[0], currentSplit[2]) # X_train_std, y_train\n",
    "\n",
    "        # test logistic regression GD model x times\n",
    "        for i in range(randomStart, randomEnd):\n",
    "\n",
    "            # put results into dict\n",
    "            y_pred = lrGD.predict(dataSplits[i][1]) # X_test_std\n",
    "\n",
    "            # append tuple (Misclassified examples, Accuracy) ==> (y_test != y_pred).sum(), accuracy_score(y_test, y_pred))\n",
    "            results.append(((dataSplits[i][3] != y_pred).sum(), accuracy_score(dataSplits[i][3], y_pred)))\n",
    "            \n",
    "        # append results to current perceptron dict\n",
    "        lrGDs[lrGD] = results\n",
    "        \n",
    "    return lrGDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce0c2712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 16\n",
      "Avg accuracy: 0.941\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on all features\n",
    "lrGDs_all = train_lrGDs(1, 11, X_all_split)\n",
    "lrGDs_all_results = print_avgs(lrGDs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52c26a78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 115\n",
      "Avg accuracy: 0.578\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on player combat -- offensive\n",
    "lrGDs_pcombatOff = train_lrGDs(1, 11, X_pcombatOff_split)\n",
    "lrGDs_pcombatOff_results = print_avgs(lrGDs_pcombatOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d3eaa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 64\n",
      "Avg accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on player combat -- defensive\n",
    "lrGDs_pcombatDef = train_lrGDs(1, 11, X_pcombatDef_split)\n",
    "lrGDs_pcombatDef_results = print_avgs(lrGDs_pcombatDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cdee781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 59\n",
      "Avg accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on player combat -- both\n",
    "lrGDs_pcombat = train_lrGDs(1, 11, X_pcombat_split)\n",
    "lrGDs_pcombat_results = print_avgs(lrGDs_pcombat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d23ac4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 117\n",
      "Avg accuracy: 0.570\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on spell casts\n",
    "lrGDs_spells = train_lrGDs(1, 11, X_spells_split)\n",
    "lrGDs_spells_results = print_avgs(lrGDs_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da5d9d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 36\n",
      "Avg accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on kda/killing sprees\n",
    "lrGDs_kda = train_lrGDs(1, 11, X_kda_split)\n",
    "lrGDs_kda_results = print_avgs(lrGDs_kda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc9939c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 95\n",
      "Avg accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression GD on vision\n",
    "lrGDs_vision = train_lrGDs(1, 11, X_vision_split)\n",
    "lrGDs_vision_results = print_avgs(lrGDs_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09ab50",
   "metadata": {},
   "source": [
    "### Logistic regression GD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59c845a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg misclassified examples</th>\n",
       "      <th>Avg accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>16.09</td>\n",
       "      <td>0.941062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA/kill streaks</th>\n",
       "      <td>36.55</td>\n",
       "      <td>0.866117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat</th>\n",
       "      <td>59.44</td>\n",
       "      <td>0.782271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (defensive)</th>\n",
       "      <td>64.87</td>\n",
       "      <td>0.762381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vision</th>\n",
       "      <td>95.80</td>\n",
       "      <td>0.649084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (offensive)</th>\n",
       "      <td>115.30</td>\n",
       "      <td>0.577656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spells casted</th>\n",
       "      <td>117.45</td>\n",
       "      <td>0.569780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Avg misclassified examples  Avg accuracy\n",
       "All features                                    16.09      0.941062\n",
       "KDA/kill streaks                                36.55      0.866117\n",
       "Player combat                                   59.44      0.782271\n",
       "Player combat (defensive)                       64.87      0.762381\n",
       "Vision                                          95.80      0.649084\n",
       "Player combat (offensive)                      115.30      0.577656\n",
       "Spells casted                                  117.45      0.569780"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrGD_results_list = [lrGDs_all_results, lrGDs_pcombatOff_results, lrGDs_pcombatDef_results, \n",
    "                  lrGDs_pcombat_results, lrGDs_spells_results, lrGDs_kda_results, lrGDs_vision_results]\n",
    "\n",
    "lrGD_results = pd.DataFrame(lrGD_results_list, index = features_about, columns = [\"Avg misclassified examples\", \"Avg accuracy\"])\n",
    "lrGD_results = lrGD_results.sort_values(by=[\"Avg accuracy\"], ascending=False)\n",
    "lrGD_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f25796",
   "metadata": {},
   "source": [
    "### Train decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eddc767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\"\"\"\n",
    "train_dts(): train n different decision tree models and test each n times\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        dataSplits - dictionary of data splits\n",
    "    output:\n",
    "        dictionary of decision tree models:\n",
    "            dts[decision tree model] = [(Misclassified examples, Accuracy)...]\n",
    "\"\"\"\n",
    "def train_dts(randomStart, randomEnd, dataSplits):\n",
    "        \n",
    "    # dts[decision tree model] = [(Misclassified examples, Accuracy)...]\n",
    "    dts = {}\n",
    "\n",
    "    for randState in dataSplits:\n",
    "\n",
    "        # current testing and training split\n",
    "        currentSplit = dataSplits[randState]\n",
    "\n",
    "        # list of models for each random state\n",
    "        results = []\n",
    "\n",
    "        # Train decision tree model\n",
    "        dt = DecisionTreeClassifier(random_state=randState)\n",
    "        dt.fit(currentSplit[0], currentSplit[2]) # X_train_std, y_train\n",
    "\n",
    "        # test decision tree model x times\n",
    "        for i in range(randomStart, randomEnd):\n",
    "\n",
    "            # put results into dict\n",
    "            y_pred = dt.predict(dataSplits[i][1]) # X_test_std\n",
    "\n",
    "            # append tuple (Misclassified examples, Accuracy) ==> (y_test != y_pred).sum(), accuracy_score(y_test, y_pred))\n",
    "            results.append(((dataSplits[i][3] != y_pred).sum(), accuracy_score(dataSplits[i][3], y_pred)))\n",
    "            \n",
    "        # append results to current perceptron dict\n",
    "        dts[dt] = results\n",
    "        \n",
    "    return dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb582852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 23\n",
      "Avg accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on all features\n",
    "dts_all = train_dts(1, 11, X_all_split)\n",
    "dts_all_results = print_avgs(dts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19d321b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 88\n",
      "Avg accuracy: 0.674\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on player combat -- offensive\n",
    "dts_pcombatOff = train_dts(1, 11, X_pcombatOff_split)\n",
    "dts_pcombatOff_results = print_avgs(dts_pcombatOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ef23f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 56\n",
      "Avg accuracy: 0.794\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on player combat -- defensive\n",
    "dts_pcombatDef = train_dts(1, 11, X_pcombatDef_split)\n",
    "dts_pcombatDef_results = print_avgs(dts_pcombatDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "892fb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 55\n",
      "Avg accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on player combat -- both\n",
    "dts_pcombat = train_dts(1, 11, X_pcombat_split)\n",
    "dts_pcombat_results = print_avgs(dts_pcombat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4528293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 79\n",
      "Avg accuracy: 0.710\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on spell casts\n",
    "dts_spells = train_dts(1, 11, X_spells_split)\n",
    "dts_spells_results = print_avgs(dts_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a330983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 26\n",
      "Avg accuracy: 0.903\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on kda/killing sprees\n",
    "dts_kda = train_dts(1, 11, X_kda_split)\n",
    "dts_kda_results = print_avgs(dts_kda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "195dfcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 55\n",
      "Avg accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "# train decision tree on vision\n",
    "dts_vision = train_dts(1, 11, X_vision_split)\n",
    "dts_vision_results = print_avgs(dts_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa9f60",
   "metadata": {},
   "source": [
    "### Decision tree results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fabb214",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg misclassified examples</th>\n",
       "      <th>Avg accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>23.00</td>\n",
       "      <td>0.915751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA/kill streaks</th>\n",
       "      <td>26.41</td>\n",
       "      <td>0.903260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vision</th>\n",
       "      <td>55.60</td>\n",
       "      <td>0.796337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat</th>\n",
       "      <td>55.67</td>\n",
       "      <td>0.796081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (defensive)</th>\n",
       "      <td>56.20</td>\n",
       "      <td>0.794139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spells casted</th>\n",
       "      <td>79.21</td>\n",
       "      <td>0.709853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (offensive)</th>\n",
       "      <td>88.95</td>\n",
       "      <td>0.674176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Avg misclassified examples  Avg accuracy\n",
       "All features                                    23.00      0.915751\n",
       "KDA/kill streaks                                26.41      0.903260\n",
       "Vision                                          55.60      0.796337\n",
       "Player combat                                   55.67      0.796081\n",
       "Player combat (defensive)                       56.20      0.794139\n",
       "Spells casted                                   79.21      0.709853\n",
       "Player combat (offensive)                       88.95      0.674176"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results_list = [dts_all_results, dts_pcombatOff_results, dts_pcombatDef_results, \n",
    "                  dts_pcombat_results, dts_spells_results, dts_kda_results, dts_vision_results]\n",
    "\n",
    "dt_results = pd.DataFrame(dt_results_list, index = features_about, columns = [\"Avg misclassified examples\", \"Avg accuracy\"])\n",
    "dt_results = dt_results.sort_values(by=[\"Avg accuracy\"], ascending=False)\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5929c",
   "metadata": {},
   "source": [
    "### Train random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55846649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "train_rfs(): train n different random forest models and test each n times\n",
    "    input:\n",
    "        randomStart - start value\n",
    "        randomEnd - end value\n",
    "        dataSplits - dictionary of data splits\n",
    "    output:\n",
    "        dictionary of random forest models:\n",
    "            rfs[random forest model] = [(Misclassified examples, Accuracy)...]\n",
    "\"\"\"\n",
    "def train_rfs(randomStart, randomEnd, dataSplits):\n",
    "        \n",
    "    # rfs[random forest model] = [(Misclassified examples, Accuracy)...]\n",
    "    rfs = {}\n",
    "\n",
    "    for randState in dataSplits:\n",
    "\n",
    "        # current testing and training split\n",
    "        currentSplit = dataSplits[randState]\n",
    "\n",
    "        # list of models for each random state\n",
    "        results = []\n",
    "\n",
    "        # Train random forest model\n",
    "        rf = RandomForestClassifier(random_state=randState)\n",
    "        rf.fit(currentSplit[0], currentSplit[2]) # X_train_std, y_train\n",
    "\n",
    "        # test random forest model x times\n",
    "        for i in range(randomStart, randomEnd):\n",
    "\n",
    "            # put results into dict\n",
    "            y_pred = rf.predict(dataSplits[i][1]) # X_test_std\n",
    "\n",
    "            # append tuple (Misclassified examples, Accuracy) ==> (y_test != y_pred).sum(), accuracy_score(y_test, y_pred))\n",
    "            results.append(((dataSplits[i][3] != y_pred).sum(), accuracy_score(dataSplits[i][3], y_pred)))\n",
    "            \n",
    "        # append results to current perceptron dict\n",
    "        rfs[rf] = results\n",
    "        \n",
    "    return rfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68640c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 12\n",
      "Avg accuracy: 0.955\n"
     ]
    }
   ],
   "source": [
    "# train random forest on all features\n",
    "rfs_all = train_rfs(1, 11, X_all_split)\n",
    "rfs_all_results = print_avgs(rfs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71c8aa2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 61\n",
      "Avg accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "# train random forest on player combat -- offensive\n",
    "rfs_pcombatOff = train_rfs(1, 11, X_pcombatOff_split)\n",
    "rfs_pcombatOff_results = print_avgs(rfs_pcombatOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0563e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 35\n",
      "Avg accuracy: 0.871\n"
     ]
    }
   ],
   "source": [
    "# train random forest on player combat -- defensive\n",
    "rfs_pcombatDef = train_rfs(1, 11, X_pcombatDef_split)\n",
    "rfs_pcombatDef_results = print_avgs(rfs_pcombatDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6a95d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 30\n",
      "Avg accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "# train random forest on player combat -- both\n",
    "rfs_pcombat = train_rfs(1, 11, X_pcombat_split)\n",
    "rfs_pcombat_results = print_avgs(rfs_pcombat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5849cedf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 63\n",
      "Avg accuracy: 0.767\n"
     ]
    }
   ],
   "source": [
    "# train random forest on spell casts\n",
    "rfs_spells = train_rfs(1, 11, X_spells_split)\n",
    "rfs_spells_results = print_avgs(rfs_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17e0c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 23\n",
      "Avg accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "# train random forest on kda/killing sprees\n",
    "rfs_kda = train_rfs(1, 11, X_kda_split)\n",
    "rfs_kda_results = print_avgs(rfs_kda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "486a6da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg misclassified examples: 44\n",
      "Avg accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# train random forest on vision\n",
    "rfs_vision = train_rfs(1, 11, X_vision_split)\n",
    "rfs_vision_results = print_avgs(rfs_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0abf7b",
   "metadata": {},
   "source": [
    "### Random forest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71453b5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg misclassified examples</th>\n",
       "      <th>Avg accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>12.20</td>\n",
       "      <td>0.955311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDA/kill streaks</th>\n",
       "      <td>23.59</td>\n",
       "      <td>0.913590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat</th>\n",
       "      <td>30.03</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (defensive)</th>\n",
       "      <td>35.16</td>\n",
       "      <td>0.871209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vision</th>\n",
       "      <td>44.86</td>\n",
       "      <td>0.835678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player combat (offensive)</th>\n",
       "      <td>61.53</td>\n",
       "      <td>0.774615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spells casted</th>\n",
       "      <td>63.69</td>\n",
       "      <td>0.766703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Avg misclassified examples  Avg accuracy\n",
       "All features                                    12.20      0.955311\n",
       "KDA/kill streaks                                23.59      0.913590\n",
       "Player combat                                   30.03      0.890000\n",
       "Player combat (defensive)                       35.16      0.871209\n",
       "Vision                                          44.86      0.835678\n",
       "Player combat (offensive)                       61.53      0.774615\n",
       "Spells casted                                   63.69      0.766703"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results_list = [rfs_all_results, rfs_pcombatOff_results, rfs_pcombatDef_results, \n",
    "                  rfs_pcombat_results, rfs_spells_results, rfs_kda_results, rfs_vision_results]\n",
    "\n",
    "rf_results = pd.DataFrame(rf_results_list, index = features_about, columns = [\"Avg misclassified examples\", \"Avg accuracy\"])\n",
    "rf_results = rf_results.sort_values(by=[\"Avg accuracy\"], ascending=False)\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7982bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
